{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:darkblue;\">\n",
    "    <h2>\n",
    "        Dapsys Importer Notebook\n",
    "    </h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/background.jpg\" width=\"800\">\n",
    "\n",
    "First time dealing with Jupyter notebooks? <a href=\"https://ukaachen-my.sharepoint.com/:w:/r/personal/ekutafina_ukaachen_de/Documents/Microneurography%20Data%20Analysis%20Team/Scripts%20documentation/Python_Jupyter_%20Manual%20for%20non-CS%20people.docx?d=wd12099523c094eafb83287b67ffc3308&csf=1&web=1&e=RPbYmq\">Click here</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkblue;\">\n",
    "    <h2>\n",
    "        Data summary\n",
    "    </h2> \n",
    "</span>\n",
    "<i>(More information available in Ukaachen drive)</i> \n",
    "\n",
    "With Dapsys Software, we’re able to extract files in .csv format, suitable for further data analysis. In the following, we’ll cover the dataset that is being extracted and its corresponding usage. There are 4 main files extracted from dapsys:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><center><h2 style=\"background-color:black; color:white;\">Continuous recording</h2></center></td>\n",
    "        <td><center><h2 style=\"background-color:black; color:white;\">Main pulses</h2></center></td>\n",
    "        <td><center><h2 style=\"background-color:black; color:red;\">Template</h2></center></td>\n",
    "        <td><center><h2 style=\"background-color:black; color:yellow;\">Track times</h2></center></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"../imgs/recordings.png\"height=\"200\"></td>\n",
    "        <td><img src=\"../imgs/pulses.png\" height=\"200\"></td>\n",
    "        <td><img src=\"../imgs/template.png\" height=\"200\"></td>\n",
    "        <td><img src=\"../imgs/track_times.png\" height=\"200\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><center>General recording. Every odd row represents timestamp and every even row represents corresponding amplitude. </center></td>\n",
    "        <td><center>Timestamps that correspond to electrical stimuli. </center></td>\n",
    "        <td><center>30-point list/vector, that contains amplitude values. We would like to find the spikes that are similar to this template. </center></td>\n",
    "        <td><center>These are timestamps that correspond to the part of the signals which we know it’s generated from electrical stimulus. </center></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkblue;\">\n",
    "    <h2>Hiding or showing the code</h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting with the data analysis, you can choose whether you want to see the actual code or not. If you want to hide the code, you can run the cell below. Bear in mind that hiding the code, could result in lack of focus and more difficult usage for beginners in Jupyter. Though, you can always hide/show the code. <b>If you appear to have just hidden code + restarted kernel (without any visibility of cells), no worries, you can just select this text-cell and move to the below one and run it.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML, display, Image, clear_output\n",
    "HTML('''\n",
    "<style>.container { width:100% !important; } div.output_area {overflow-y: scroll;} div.output_area img {max-width: unset;} </style>\n",
    "<script>code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){$('div.input').hide();} else {$('div.input').show();}\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<p style=\"color:red\"><strong>To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.</p></strong>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:darkblue;\">\n",
    "<h2>Step 1: Define path of your 4 files</h2>\n",
    "</span>\n",
    "\n",
    "So you would want to have all of the four files within the same directory. Please note that for successful reading of the files, you must name corresponding files with endings as follows: pulses, track, template, recording. For instance: \n",
    "\n",
    "<img src=\"../imgs/naming.png\">\n",
    "\n",
    "After you run the cell, a text-box should appear, with a default value of a path. If you would like to assess new files, please make a separate folder in \"Dapsys/data\" folder, and then type in the path in the text box. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "tag"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from importers import DapsysImporter\n",
    "from plotting import *\n",
    "\n",
    "text_path = widgets.Text(description='Insert path:', value='../data/alternative_3')\n",
    "out_path = widgets.Output()\n",
    "widgets.VBox([text_path, out_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you move to the next cell and run it, it will automatically try to gather data in necessary format for analysis. You should get an output which says that all four files are being read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "dapsys = DapsysImporter(dir_path = text_path.value)\n",
    "trck_dict = dapsys.extract_segment_idxs_times()\n",
    "freq = round((dapsys.point_data[1][0] - dapsys.point_data[0][0]) * 1000, 5)\n",
    "correct_signals = dapsys.get_action_potentials()\n",
    "\n",
    "correct_signals_dict = convert_signals_to_dict(correct_signals, dapsys.main_pulses, freq, full_scale=False, template=dapsys.template, trck_dict=None)\n",
    "template_dict = convert_template_to_dict(dapsys.template, freq)\n",
    "traces = find_traces_amplitudes(correct_signals_dict+[template_dict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:darkblue;\">\n",
    "    <h2>\n",
    "        Step 2: Define threshold for AP identification\n",
    "    </h2>\n",
    "</span>\n",
    "Next step is to manually define a threshold for identifying an action potential. More on the actual method can be found in the documentation. Run the cell below to activate the possibility of choosing a threshold. By default it is 5. To choose a \"good threshold value\", after running the cell, you will be able to see the all the correct signals (generated from track times) and their corresponding shape, latency, segment in which they appeared (stimulus-to-stimulus window) and finally correlation with the <span style=\"color:red;\">template.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "graph1=go.FigureWidget(data=traces, layout=go.Layout(width=800, height=400, title=dict(text='Template and correct spikes'), \n",
    "                                                xaxis=dict(title='Time (ms)', range=[0, 3-freq]), \n",
    "                                                yaxis=dict(title='Amplitude', range=[-10, 10]), barmode='overlay'))\n",
    "\n",
    "slider_templ = widgets.FloatSlider(description='Threshold:', min=1, max=10, step=0.05, value =5)\n",
    "button_templ = widgets.Button(description='Find spikes')\n",
    "widgets.VBox([graph1, slider_templ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run the cell below this one, you'll extract the data in necessary format for visualization and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "threshold = slider_templ.value\n",
    "print(f'Getting spikes with threshold of {threshold}...')\n",
    "taps = dapsys.get_threshold_action_potentials(threshold)\n",
    "\n",
    "taps_dict = convert_signals_to_dict(taps, dapsys.main_pulses, freq, full_scale=True, template=dapsys.template, trck_dict=trck_dict)\n",
    "threshold_dict = convert_threshold_to_dict(threshold, 40000, freq)\n",
    "sigs_dict = taps_dict+[threshold_dict]\n",
    "\n",
    "amplitudes_list = dapsys.get_raw_signal_split_by_stimuli()\n",
    "times_list = dapsys.get_raw_timestamp_split_by_stimuli()\n",
    "tap_corrs = [tap['corr'] for tap in taps_dict]\n",
    "real_corrs = [tap['corr'] for tap in correct_signals_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:darkblue;\">\n",
    "    <h2>\n",
    "        Visualization 1: Main pulse divided signal recording, with APs\n",
    "    </h2>\n",
    "</span>\n",
    "\n",
    "This is the main visualization of the actual recording, which is being split by segment. Here, \"Segment\" corresponds to time period between the two electrical stimuli. When you run the following cell, you will firstly see the first segment. There is a possibility to use slider to switch to some other segment. Manually found APs are colored in green, whereas the ones from electrical stimulus are colored in yellow with 👌 symbol. Using the list on the right, one can examine the correlation and time latency to an electrical stimulus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "segments_main = widgets.IntSlider(value=1, min=1, max=len(amplitudes_list), step=1, description='Segment:', continuous_update=False)\n",
    "container_main = widgets.HBox(children=[segments_main])\n",
    "g = big_plot(dapsys, sigs_dict, amplitudes_list, freq)\n",
    "fp = functools.partial(update_big_plot, g=g, amplitudes_list = amplitudes_list, \n",
    "                       segments_main = segments_main, freq = freq, sigs_dict = sigs_dict)\n",
    "segments_main.observe(fp, names='value')\n",
    "display(widgets.VBox([container_main, g]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:darkblue;\">\n",
    "    <h2>\n",
    "        Visualization 2: Histogram/Distribution plot of manually found and correct APs\n",
    "    </h2>\n",
    "</span>\n",
    "\n",
    "Now, given the <span style=\"color:green;\">manually found APs</span> and <span style=\"background-color:gray; color:yellow;\">\"correct ones\"</span> (from track_times.csv file)</span>, we can use following visualizations for further examination:<br/>\n",
    "\n",
    "- Using histogram and boxplot of correlation values between APs \n",
    "- Directly plotting the signal\n",
    "\n",
    "In addition, a slider below the plots, can be used to extract higher correlation points. To do so, just slide the slider to a higher point: Both plots should change accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig1, fig2 = histo_signal_plot(dapsys, tap_corrs, real_corrs, freq, taps, trck_dict)\n",
    "\n",
    "\n",
    "out_mod = widgets.Output()\n",
    "button_mod = widgets.Button(description='Modify threshold!', layout=widgets.Layout(width='200px', height='40px'))\n",
    "slider_mod = widgets.FloatSlider(description='Correlation:', min=0.3, max=1, step=0.05)\n",
    "fp2 = functools.partial(histo_signal_plot_update, out_mod=out_mod, slider_mod=slider_mod, dapsys=dapsys, \n",
    "                         freq=freq, trck_dict=trck_dict, \n",
    "                         fig1=fig1, fig2=fig2, tap_corrs=tap_corrs, taps=taps)\n",
    "\n",
    "button_mod.on_click(fp2)\n",
    "display(widgets.VBox(children=[fig1, fig2, out_mod, slider_mod, button_mod]))\n",
    "display(HTML('<i>(Could be slow in case of too many signals)<i>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell is being ran for the purpose of data wrangling for visualizing remaining useful plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "track_df = pd.DataFrame(dict_to_df(correct_signals, dapsys.template.signal_template), columns=['segment_id', 'Time (s)', 'Correlation']).astype({'segment_id': 'int32'})\n",
    "thresh_df = pd.DataFrame(dict_to_df(taps, dapsys.template.signal_template), columns=['segment_id', 'Time (s)', 'Correlation']).astype({'segment_id': 'int32'})\n",
    "idxs = thresh_df.segment_id.unique()\n",
    "min_idx = min(idxs); max_idx = max(idxs)\n",
    "mapping = {l:m for m,l in enumerate(idxs)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:darkblue;\">\n",
    "    <h2>\n",
    "        Visualization 3: Delay - Correlation plot (correct signals)\n",
    "    </h2>\n",
    "</span>\n",
    "\n",
    "In the following cell, you will get a visualization that explains latency-correlation relationship of the <span style=\"background-color:gray;color:yellow;\">correct action potentials</span>.\n",
    "The lighter the point - later it appears (In terms of the segment index). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "px.scatter(track_df, labels=\"segment_id\", x=\"Time (s)\", y=\"Correlation\", color='segment_id', hover_data=['segment_id'], range_x=[0,4], range_y=[0,1], title=\"Correct signals correlation\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:darkblue;\">\n",
    "    <h2>\n",
    "        Visualization 4: Delay - Correlation plot (manually found APs)\n",
    "    </h2>\n",
    "</span>\n",
    "\n",
    "Now, you will be able to assess the same relationship, but with <span style=\"color:green;\">manually found APs</span>.\n",
    "\n",
    "By default, only the first segment is being selected, and other ones faded. To change the segment, select the slider and click \"Set active segment\". To see all of the points more clearly, click \"Set all segments active\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "gg = reaction_plot_threshold(thresh_df)\n",
    "segment_slider_act = widgets.IntSlider(description='Segment:', min=min_idx, max=max_idx)\n",
    "button_act1 = widgets.Button(description='Set active segment!', layout=widgets.Layout(width='200px', height='40px'))\n",
    "button_act2 = widgets.Button(description='Set all segments active!', layout=widgets.Layout(width='200px', height='40px'))\n",
    "out_act2 = widgets.Output()\n",
    "\n",
    "fp3 = functools.partial(delay_plot_set_active_segment, \n",
    "                        out_act = out_act2, g = gg, segment_slider_act = segment_slider_act, \n",
    "                        mapping = mapping, idxs = idxs)\n",
    "\n",
    "fp4 = functools.partial(delay_plot_set_all_segments_active,\n",
    "                        out_act = out_act2, g = gg, idxs = idxs)\n",
    "\n",
    "button_act1.on_click(fp3)\n",
    "button_act2.on_click(fp4)\n",
    "container = widgets.HBox([button_act1, button_act2])\n",
    "display(widgets.VBox([gg, out_act2, segment_slider_act, container]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:darkblue;\">\n",
    "    <h2>\n",
    "        Step 3 (optional): Save manually found APs in excel table\n",
    "    </h2>\n",
    "</span>\n",
    "\n",
    "Finally, you can extract these <span style=\"color:green;\">manually found APs</span>, in a table, ready for excel extraction. To extract it as an excel file, type in the textbox, name of the file that you would like to use. After clicking \"Save table as an excel file\", you can access it, from the same folder that this notebook is in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "text_act = widgets.Text(description='Insert path:', value='test')\n",
    "out_act3 = widgets.Output()\n",
    "fp5 = functools.partial(save_excel, out_act = out_act3, thresh_df = thresh_df, text_act = text_act)\n",
    "button_act3 = widgets.Button(description='Save table as excel file', layout=widgets.Layout(width='200px', height='40px'))\n",
    "button_act3.on_click(fp5)\n",
    "\n",
    "display(HTML(\"<br/>\"))\n",
    "display(thresh_df[['segment_id', 'Time (s)', 'Correlation']])\n",
    "display(widgets.VBox([text_act, out_act3, button_act3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "rise": {
   "height": 100,
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
