{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of eletrical stimuli created.\n",
      "List of extra eletrical stimuli created.\n",
      "Finished processing AP channel 1 out of 1\n",
      "List of APs created.\n",
      "Done with cropping the intervals\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from gui import SpikeImportGUI\n",
    "from importers import SpikeImporter\n",
    "from recordings import MNGRecording\n",
    "\n",
    "# present the Spike GUI and let the user make his choices\n",
    "spike_gui = SpikeImportGUI()\n",
    "\n",
    "importer = SpikeImporter(filepath = spike_gui.filepath, time_channel = spike_gui.time_channel, signal_channel = spike_gui.signal_channel)\n",
    "    \n",
    "recording = MNGRecording.from_importer(importer = importer, stimulus_channels = spike_gui.stimulus_channels, \\\n",
    "                                      ap_channels = spike_gui.ap_channels, force_threshold = spike_gui.force_threshold, \\\n",
    "                                      max_ap_gap_time = spike_gui.max_ap_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 227/227 [00:00<00:00, 32379.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from every AP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Here, we extract some features from the APs:\n",
    "- postpulse distance (aka latency)\n",
    "- normalized signal energy\n",
    "'''\n",
    "%autoreload 2\n",
    "from tqdm import tqdm\n",
    "from feature_extraction import calc_dist_to_prev_reg_el_stimulus, calc_normalized_energy\n",
    "\n",
    "print(\"Extracting features from every AP\")\n",
    "\n",
    "# all_el_stimuli = el_stimuli.copy()\n",
    "# all_el_stimuli.extend(importer.get_electrical_stimuli(regular_stimulus_channel = extra_stimuli_channel))\n",
    "\n",
    "for ap in tqdm(recording.actpots):\n",
    "    ap.features[\"latency\"], ap.prev_stimuli[\"regular\"] = calc_dist_to_prev_reg_el_stimulus(ap, recording.el_stimuli)\n",
    "    ap.features[\"energy\"] = calc_normalized_energy(ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfe62da46af4ff7873a29e002846694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.005, description='eps', max=0.05, min=0.001, readout_format='.3f', s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' \n",
    "This cell performs the clustering according to\n",
    "- distance to previous stimulus\n",
    "- normalized signal energy of the APs\n",
    "'''\n",
    "%autoreload 2\n",
    "from fibre_tracking import DBSCANClustering\n",
    "from ipywidgets import interact_manual, fixed, IntSlider, FloatSlider\n",
    "\n",
    "dbscan = DBSCANClustering()\n",
    "x = interact_manual(dbscan.perform_clustering, actpots = fixed(recording.actpots), \\\n",
    "                eps = FloatSlider(min = 0.001, max = 0.05, step = 0.001, value = 0.005, readout_format='.3f'), \\\n",
    "                min_samples = IntSlider(min = 1, max = 50, value = 10, step = 1), \\\n",
    "                save_fibre_prediction = fixed(True), \\\n",
    "                plot_results = fixed(True), \\\n",
    "                manual_name = \"Update Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf81fbb734144f4a575406f2a0c433e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='t_start', max=440.0), IntSlider(value=5, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from plotting import FallingLeafPlot\n",
    "from ipywidgets import interact_manual, fixed, IntSlider, FloatSlider\n",
    "\n",
    "tmin, tmax = importer.get_time_range()\n",
    "max_interval_length = max([stim.interval_length for stim in recording.el_stimuli])\n",
    "\n",
    "flplot = FallingLeafPlot()\n",
    "interact_manual(flplot.plot, regular_stimuli = fixed(recording.el_stimuli), action_potentials = fixed(recording.actpots), \\\n",
    "                t_start = FloatSlider(min = tmin, max = tmax, value = 0), \\\n",
    "                num_intervals = IntSlider(min = 1, max = len(recording.el_stimuli), step = 1, value = 5), \\\n",
    "                post_stimulus_timeframe = FloatSlider(min = 0, max = max_interval_length, value = 0.1), \\\n",
    "                manual_name = \"Update Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabia\\Desktop\\Uni\\neuro_hiwi\\imi-neuro\\code\\fibre_tracking\\ap_template.py:28: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  avg_len = ceil(np.sum([len(ap.raw_signal) for ap in aps]) / num_aps)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2ff08ea1e979>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mfiltered_aps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0map\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimplied_fibre_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcluster_idcs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecording\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactpots\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtemplate_candidate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mActionPotentialTemplate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_ap_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered_aps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtemplate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemplate_candidate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal_template\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Uni\\neuro_hiwi\\imi-neuro\\code\\fibre_tracking\\ap_template.py\u001b[0m in \u001b[0;36mfrom_ap_list\u001b[1;34m(aps)\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[0mavg_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_signal\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0map\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maps\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_aps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m                 \u001b[0mavg_argmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_signal\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0map\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maps\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_aps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from fibre_tracking import ActionPotentialTemplate\n",
    "from metrics import normalized_cross_correlation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get the APs for a certain cluster number\n",
    "cluster_idcs = [0]\n",
    "filtered_aps = list(filter(lambda ap: ap.implied_fibre_index in cluster_idcs, recording.actpots))\n",
    "\n",
    "template_candidate = ActionPotentialTemplate.from_ap_list(aps = filtered_aps)\n",
    "    \n",
    "template = template_candidate.signal_template\n",
    "corr = np.array([normalized_cross_correlation(template, ap.raw_signal) for ap in recording.actpots])\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(x = corr, bins = 100)\n",
    "plt.grid(axis = 'both')\n",
    "plt.xlabel(\"Normalized correlation coefficient\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of correlation for the fibre candidate template\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Try to perform some linear regression using the spike counts\n",
    "'''\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from feature_extraction import get_adaptive_spike_count\n",
    "from machine_learning import timebased_train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for ap in recording.actpots:\n",
    "    ap.features[\"spikecount\"] = get_adaptive_spike_count(actpot = ap, actpots = recording.actpots, timeframe = 1600, num_splits = 16)\n",
    "#    ap.features[\"spikecount\"] = get_spike_count(actpot = ap, actpots = actpots, timeframe = 800, num_intervals = 16)\n",
    "    \n",
    "# restrict to only the \"interesting\" APs that we suspect as candidates\n",
    "candidate_aps = [ap for ap in recording.actpots if ap.implied_fibre_index == 0]\n",
    "\n",
    "# get the features as lists\n",
    "spike_counts = [ap.features[\"spikecount\"] for ap in candidate_aps]\n",
    "latencies = [ap.features[\"latency\"] for ap in candidate_aps]\n",
    "\n",
    "# perform a split on the set to get some data for training and some for evaluation\n",
    "train_aps, test_aps = timebased_train_test_split(candidate_aps, test_percentage = 0.3, num_test_intervals = 10)\n",
    "\n",
    "cnts_train = [ap.features[\"spikecount\"] for ap in train_aps]\n",
    "lat_train = [ap.features[\"latency\"] for ap in train_aps]\n",
    "cnts_test = [ap.features[\"spikecount\"] for ap in test_aps]\n",
    "lat_test = [ap.features[\"latency\"] for ap in test_aps]\n",
    "\n",
    "# plot the segments that have been selected for training and testing\n",
    "plt.figure()\n",
    "plt.scatter([ap.onset for ap in train_aps], [ap.features[\"latency\"] for ap in train_aps], label = \"Training\")\n",
    "plt.scatter([ap.onset for ap in test_aps], [ap.features[\"latency\"] for ap in test_aps], label = \"Test\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# we should not use this sklearn function because it samples random data points from anywhere in the recording\n",
    "# cnts_train, cnts_test, lat_train, lat_test = train_test_split(spike_counts, latencies, test_size = 0.2)\n",
    "\n",
    "regression = LinearRegression().fit(X = cnts_train, y = lat_train)\n",
    "\n",
    "lat_pred = regression.predict(cnts_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(lat_test, lat_pred)\n",
    "plt.gca().plot([0, 1], [0, 1], transform = plt.gca().transAxes, color = \"r\")\n",
    "plt.xlabel(\"Observed Latency (ms)\")\n",
    "plt.ylabel(\"Predicted Latency (ms)\")\n",
    "plt.title(\"R^2 score: \" + \"{:.2f}\".format(r2_score(lat_test, lat_pred)))\n",
    "plt.gca().set_ylim(ymin=0)\n",
    "plt.gca().set_xlim(xmin=0)\n",
    "plt.show()\n",
    "\n",
    "print(len(cnts_train))\n",
    "\n",
    "print(len(cnts_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction import get_spike_count\n",
    "\n",
    "# restrict to only the \"interesting\" APs that we suspect as candidates\n",
    "candidate_aps = [ap for ap in recording.actpots if ap.implied_fibre_index == 0]\n",
    "\n",
    "timeframe_len = 400\n",
    "\n",
    "spike_counts = [get_spike_count(actpot = ap, actpots = recording.actpots, timeframe = timeframe_len, num_intervals = 1) for ap in candidate_aps]\n",
    "latencies = [ap.features[\"latency\"] for ap in candidate_aps]\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(spike_counts, latencies)\n",
    "plt.xlabel(\"Number of action potentials in previous \" + str(timeframe_len) + \"s\")\n",
    "plt.ylabel(\"Latency of response to stimulus (s)\")\n",
    "plt.gca().set_ylim(ymin=0)\n",
    "plt.gca().set_xlim(xmin=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
